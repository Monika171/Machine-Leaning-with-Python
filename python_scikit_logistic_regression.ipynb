{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python-scikit-logistic-regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monika171/Machine-Learning-with-Python/blob/main/python_scikit_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPxwVks_Tojr",
        "outputId": "42c8fb72-9e7b-4174-daea-40dbd622a8d7"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('python-scikit-logistic-regression')\n",
        "jovian.set_colab_id('1e_tIcdXkbVmH8BqDbEItoGdj1IWx9s5S')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 23.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.1MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW7O13sJnXng"
      },
      "source": [
        "# python-scikit-logistic-regression\n",
        "\n",
        "Use the \"Run\" button to execute the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypqJbhponw8K"
      },
      "source": [
        "# Logistic Regression with Scikit Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHiA8fgxvHR4"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "This tutorial takes a practical and coding-focused approach. We'll learn how to apply _logistic regression_ to a real-world dataset from [Kaggle](https://kaggle.com/datasets):\n",
        "\n",
        "> **QUESTION**: The [Rain in Australia dataset](https://kaggle.com/jsphyg/weather-dataset-rattle-package) contains about 10 years of daily weather observations from numerous Australian weather stations. Here's a small sample from the dataset:\n",
        "> \n",
        "> ![](https://i.imgur.com/5QNJvir.png)\n",
        ">\n",
        "> As a data scientist at the Bureau of Meteorology, let's assume we are tasked with creating a fully-automated system that can use today's weather data for a given location to predict whether it will rain at the location tomorrow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIdR1FZBvo6z"
      },
      "source": [
        "## Linear Regression vs. Logistic Regression\n",
        "\n",
        "Identifying whether a given problem is a _classfication_ or _regression_ problem is an important first step in machine learning.\n",
        "\n",
        "### Classification Problems\n",
        "\n",
        "\n",
        "Problems where each input must be assigned a discrete category (also called label or class) are known as _classification problems_. \n",
        "\n",
        "Here are some examples of classification problems:\n",
        "\n",
        "- [Rainfall prediction](https://kaggle.com/jsphyg/weather-dataset-rattle-package): Predicting whether it will rain tomorrow using today's weather data (classes are \"Will Rain\" and \"Will Not Rain\")\n",
        "- [Breast cancer detection](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data): Predicting whether a tumor  is \"benign\" (noncancerous) or \"malignant\" (cancerous) using information like its radius, texture etc.\n",
        "- [Loan Repayment Prediction](https://www.kaggle.com/c/home-credit-default-risk) - Predicting whether applicants will repay a home loan based on factors like age, income, loan amount, no. of children etc.\n",
        "- [Handwritten Digit Recognition](https://www.kaggle.com/c/digit-recognizer) - Identifying which digit from 0 to 9 a picture of handwritten text represents.\n",
        "\n",
        "### Regression Problems\n",
        "\n",
        "Problems where a continuous numeric value must be predicted for each input are known as _regression problems_.\n",
        "\n",
        "Here are some example of regression problems:\n",
        "\n",
        "- [Medical Charges Prediction](https://www.kaggle.com/subhakarks/medical-insurance-cost-analysis-and-prediction)\n",
        "- [House Price Prediction](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) \n",
        "- [Ocean Temperature Prediction](https://www.kaggle.com/sohier/calcofi)\n",
        "- [Weather Temperature Prediction](https://www.kaggle.com/budincsevity/szeged-weather)\n",
        "\n",
        "Can you think of some more regression problems?\n",
        "\n",
        "> **EXERCISE**: Replicate the steps followed in the [previous tutorial](https://jovian.ai/aakashns/python-sklearn-linear-regression) with each of the above datasets.\n",
        "\n",
        "### Linear Regression for Solving Regression Problems\n",
        "\n",
        "Linear regression is a commonly used technique for solving regression problems. In a linear regression model, the target is modeled as a linear combination (or weighted sum) of input features. The predictions from the model are evaluated using a loss function like the Root Mean Squared Error (RMSE).\n",
        "\n",
        "### Logistic Regression for Solving Classification Problems\n",
        "\n",
        "Logistic regression is a commonly used technique for solving binary classification problems. In a logistic regression model: \n",
        "\n",
        "- we take linear combination (or weighted sum of the input features) \n",
        "- we apply the sigmoid function to the result to obtain a number between 0 and 1\n",
        "- this number represents the probability of the input being classified as \"Yes\"\n",
        "- instead of RMSE, the cross entropy loss function is used to evaluate the results\n",
        "\n",
        "The sigmoid function applied to the linear combination of inputs has the following formula:\n",
        "\n",
        "<img src=\"https://i.imgur.com/sAVwvZP.png\" width=\"400\">\n",
        "\n",
        "\n",
        "The output of the sigmoid function is called a logistic, hence the name _logistic regression_. Logistic regression can also be applied to multi-class classification problems, with a few modifications.\n",
        "\n",
        "===========================\n",
        "Summary:\n",
        "> Previously to predict a person's annual medical charges ---> linear regression.\n",
        "\n",
        "> Here we'll use logistic regression, which is better suited for classification problems like predicting whether it will rain tomorrow.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4LX2Mu12dH"
      },
      "source": [
        "### Machine Learning Workflow\n",
        "\n",
        "Whether we're solving a regression problem using linear regression or a classification problem using logistic regression, the workflow for training a model is exactly the same:\n",
        "\n",
        "1. We initialize a model with random parameters (weights & biases).\n",
        "2. We pass some inputs into the model to obtain predictions.\n",
        "3. We compare the model's predictions with the actual targets using the loss function.  \n",
        "4. We use an optimization technique (like least squares, gradient descent etc.) to reduce the loss by adjusting the weights & biases of the model\n",
        "5. We repeat steps 1 to 4 till the predictions from the model are good enough.\n",
        "\n",
        "\n",
        "<img src=\"https://www.deepnetts.com/blog/wp-content/uploads/2019/02/SupervisedLearning.png\" width=\"480\">\n",
        "\n",
        "\n",
        "Classification and regression are both supervised machine learning problems, because they use labeled data. Machine learning applied to unlabeled data is known as unsupervised learning ([image source](https://au.mathworks.com/help/stats/machine-learning-in-matlab.html)). \n",
        "\n",
        "<img src=\"https://i.imgur.com/1EMQmAw.png\" width=\"480\">\n",
        "\n",
        "\n",
        "Now, we'll finally train a _logistic regression_ model using the Rain in Australia dataset to predict whether or not it will rain at a location tomorrow, using today's data. This is a _binary classification_ problem.\n",
        "\n",
        "Let's install the `scikit-learn` library which we'll use to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnjZ8UA5EYDR",
        "outputId": "33d29a9a-4dba-41fc-d7d1-40546cea99c8"
      },
      "source": [
        "!pip install scikit-learn --upgrade --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 22.3MB 1.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ZX4jTcEmB0"
      },
      "source": [
        "## Downloading the Data\n",
        "\n",
        "We'll use the [`opendatasets` library](https://github.com/JovianML/opendatasets) to download the data from Kaggle directly within Jupyter. Let's install and import `opendatasets`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Blm7o4EYA6"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRy3EoiGEX_B"
      },
      "source": [
        "import opendatasets as od"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3LE9Q_EdEX8D",
        "outputId": "475cd36f-4b7e-4829-a84f-f0a1e2355037"
      },
      "source": [
        "od.version()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.1.20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9Cbnq8E9eO"
      },
      "source": [
        "The dataset can now be downloaded using `od.download`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJi6JjkbEX5d"
      },
      "source": [
        "dataset_url = 'https://www.kaggle.com/jsphyg/weather-dataset-rattle-package'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYES74zQEX3X",
        "outputId": "7b4314db-84b0-44d2-ed16-e8c54da4ffc0"
      },
      "source": [
        "od.download(dataset_url)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: monika171\n",
            "Your Kaggle Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.83M/3.83M [00:00<00:00, 196MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading weather-dataset-rattle-package.zip to ./weather-dataset-rattle-package\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgpUXN01FW71"
      },
      "source": [
        "Once the above command is executed, the dataset is downloaded and extracted to the the directory `weather-dataset-rattle-package`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoyUYNnEX0h"
      },
      "source": [
        "import os"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJecy2bxEXyO"
      },
      "source": [
        "data_dir = './weather-dataset-rattle-package'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEsGW_hREXvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a12f672-a2e8-4085-95cd-f1a8fefdd259"
      },
      "source": [
        "os.listdir(data_dir)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['weatherAUS.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4oexATXEXtk"
      },
      "source": [
        "train_csv = data_dir + '/weatherAUS.csv'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcIRzS2TVKRA"
      },
      "source": [
        "\n",
        "Let's load the data from `weatherAUS.csv` using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjDmignZEXrR"
      },
      "source": [
        "!pip install pandas --quiet"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kzomO2XEXpC"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVYCK_eYEXms"
      },
      "source": [
        "raw_df = pd.read_csv(train_csv)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnLkjmVXEXjl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "fe5b8032-20c0-4e6f-ed39-3daeffea219d"
      },
      "source": [
        "raw_df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145455</th>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>2.8</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E</td>\n",
              "      <td>31.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1024.6</td>\n",
              "      <td>1020.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1</td>\n",
              "      <td>22.4</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145456</th>\n",
              "      <td>2017-06-22</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>3.6</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NNW</td>\n",
              "      <td>22.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1023.5</td>\n",
              "      <td>1019.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145457</th>\n",
              "      <td>2017-06-23</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>5.4</td>\n",
              "      <td>26.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>37.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>WNW</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>1016.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.5</td>\n",
              "      <td>26.1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145458</th>\n",
              "      <td>2017-06-24</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>7.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145459</th>\n",
              "      <td>2017-06-25</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>14.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ESE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1020.2</td>\n",
              "      <td>1017.9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.9</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145460 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date Location  MinTemp  ...  Temp3pm  RainToday  RainTomorrow\n",
              "0       2008-12-01   Albury     13.4  ...     21.8         No            No\n",
              "1       2008-12-02   Albury      7.4  ...     24.3         No            No\n",
              "2       2008-12-03   Albury     12.9  ...     23.2         No            No\n",
              "3       2008-12-04   Albury      9.2  ...     26.5         No            No\n",
              "4       2008-12-05   Albury     17.5  ...     29.7         No            No\n",
              "...            ...      ...      ...  ...      ...        ...           ...\n",
              "145455  2017-06-21    Uluru      2.8  ...     22.4         No            No\n",
              "145456  2017-06-22    Uluru      3.6  ...     24.5         No            No\n",
              "145457  2017-06-23    Uluru      5.4  ...     26.1         No            No\n",
              "145458  2017-06-24    Uluru      7.8  ...     26.0         No            No\n",
              "145459  2017-06-25    Uluru     14.9  ...     20.9         No           NaN\n",
              "\n",
              "[145460 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB18xLrFVlxK"
      },
      "source": [
        "The dataset contains over 145,000 rows and 23 columns. The dataset contains date, numeric and categorical columns. Our objective is to create a model to predict the value in the column `RainTomorrow`.\n",
        "\n",
        "Let's check the data types and missing values in the various columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMArKNxrEXhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45931ee-8a5e-4d1d-8333-386eaa268274"
      },
      "source": [
        "raw_df.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Date           145460 non-null  object \n",
            " 1   Location       145460 non-null  object \n",
            " 2   MinTemp        143975 non-null  float64\n",
            " 3   MaxTemp        144199 non-null  float64\n",
            " 4   Rainfall       142199 non-null  float64\n",
            " 5   Evaporation    82670 non-null   float64\n",
            " 6   Sunshine       75625 non-null   float64\n",
            " 7   WindGustDir    135134 non-null  object \n",
            " 8   WindGustSpeed  135197 non-null  float64\n",
            " 9   WindDir9am     134894 non-null  object \n",
            " 10  WindDir3pm     141232 non-null  object \n",
            " 11  WindSpeed9am   143693 non-null  float64\n",
            " 12  WindSpeed3pm   142398 non-null  float64\n",
            " 13  Humidity9am    142806 non-null  float64\n",
            " 14  Humidity3pm    140953 non-null  float64\n",
            " 15  Pressure9am    130395 non-null  float64\n",
            " 16  Pressure3pm    130432 non-null  float64\n",
            " 17  Cloud9am       89572 non-null   float64\n",
            " 18  Cloud3pm       86102 non-null   float64\n",
            " 19  Temp9am        143693 non-null  float64\n",
            " 20  Temp3pm        141851 non-null  float64\n",
            " 21  RainToday      142199 non-null  object \n",
            " 22  RainTomorrow   142193 non-null  object \n",
            "dtypes: float64(16), object(7)\n",
            "memory usage: 25.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkVWOltEXe-"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bWD7fkIEXcV"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo3ClIc1EXZz"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC1LuZotEXXb"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SD59WVdEXVE"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4cDOghEXSi"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHFQOV7EXPW"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj96C7IrEXMz"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVQmYAwhEXKT"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCM11F9LEXHl"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys7I4R8vEXFY"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OasCipAxEXCt"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6-mscmXEXAW"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_aQSENgEW91"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVuV2mGqEW6y"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7ezEfJBEW4G"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQm0Mn4-nXng"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sen5IN8SnXni"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Y2MxRJXNnXnj",
        "outputId": "ad966a0b-adf6-40b5-d1dd-49a6fc70b7fb"
      },
      "source": [
        "# Execute this to save new versions of the notebook\n",
        "jovian.commit(project=\"python-scikit-logistic-regression\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "Committed successfully! https://jovian.ai/monika171/python-scikit-logistic-regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/python-scikit-logistic-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fj2vSVgnXnl"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}